{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cgitb import text\n",
    "from numpy import append\n",
    "from requests import request\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "import uuid\n",
    "import os\n",
    "import json\n",
    "import urllib.request\n",
    "import urllib\n",
    "\n",
    "class Scraper:\n",
    "\n",
    "    def __init__(self, URL : str, driver : webdriver.Chrome):\n",
    "        \n",
    "        self.driver = driver\n",
    "        self.driver_list = []\n",
    "        self.team_list = []\n",
    "        self.URL = URL\n",
    "        self.driver_dict={}\n",
    "        self.teams_dict = {}\n",
    "        self.champs_dict = {}\n",
    "        self.dict_entry = {}\n",
    "        \n",
    "\n",
    "    def load_and_accept_cookies(self) -> None:\n",
    "\n",
    "        #Open site and accept the cookies\n",
    "        \n",
    "        self.driver.get(self.URL)\n",
    "        accept_button = self.driver.find_element(by=By.XPATH, value=\"//*[@class='btn btn-success acceptGdpr']\")\n",
    "        accept_button.click()\n",
    "        \n",
    "\n",
    "\n",
    "    def navigate_drivers(self): # navigates to the list of drivers\n",
    "\n",
    "        self.driver.get(self.URL)\n",
    "        navbar = self.driver.find_element(by=By.XPATH, value=\"//div[@class='navbar-nav']\")\n",
    "        drivers_button= navbar.find_element(by=By.LINK_TEXT, value = 'Drivers')\n",
    "        drivers_button.click()\n",
    "        self.get_driver_images()\n",
    "        #self.get_driver_data()\n",
    "        \n",
    "    def get_driver_images(self):\n",
    "\n",
    "        starting_letter_tag = self.driver.find_elements(by=By.XPATH, value=\"//div[@class='col-sm-6 col-md-4']\")\n",
    "\n",
    "        for pilot in starting_letter_tag: #collects all the drivers URLS in a list\n",
    "\n",
    "            a_tag = pilot.find_element(By.TAG_NAME, 'a')\n",
    "            link = a_tag.get_attribute('href')\n",
    "            self.driver_list.append(link)\n",
    "       \n",
    "        for link in self.driver_list: #loops through every URL in the list and scrapes the statistics\n",
    "            self.driver.get(link)\n",
    "            img_src = self.driver.find_element(by=By.XPATH, value=\"//img[@class='col-md-3']\")\n",
    "            img = img_src.get_attribute('src')\n",
    "            self.download_image(img, \"/home/andrew/AICore_work/Data-Collection-Pipeline/driver_images/\", self.get_driver_name())\n",
    "    \n",
    "\n",
    "    def download_image(self, url, file_path, file_name):\n",
    "        full_path = file_path + file_name + '.jpg'\n",
    "        urllib.request.urlretrieve(url, full_path)\n",
    "    \n",
    "    def get_driver_name(self) -> str: #gets the Drivers Name and splits it into First name, Surname and adds it to dictionary\n",
    "        \n",
    "        Page_Title = self.driver.find_element(by=By.XPATH, value=\"//h1[@class='page-title']\")\n",
    "        Name = Page_Title.text\n",
    "        Name.replace(\"Formula 1 Driver\", \"\")\n",
    "        Driver_Forename = Name.split()[0]\n",
    "        Driver_Surname = \" \".join(Name.split()[1:len(Name.split())-3])\n",
    "\n",
    "        self.dict_entry[\"Driver First Name\"] = Driver_Forename\n",
    "        self.dict_entry[\"Driver Second Name\"] = Driver_Surname\n",
    "        return Driver_Forename + \"_\" + Driver_Surname\n",
    "    \n",
    "    def get_driver_data(self):\n",
    "        \n",
    "        #creates directory for driver data\n",
    "        directory = \"driver_data\"\n",
    "        parent_dir = \"/home/andrew/AICore_work/Data-Collection-Pipeline/raw_data\"\n",
    "        path = os.path.join(parent_dir, directory)\n",
    "        raw_data = os.mkdir(path)\n",
    "\n",
    "        #find element containing individual driver URLS\n",
    "        starting_letter_tag = self.driver.find_elements(by=By.XPATH, value=\"//div[@class='col-sm-6 col-md-4']\")\n",
    "\n",
    "        for pilot in starting_letter_tag: #collects all the drivers URLS in a list\n",
    "\n",
    "            a_tag = pilot.find_element(By.TAG_NAME, 'a')\n",
    "            link = a_tag.get_attribute('href')\n",
    "            self.driver_list.append(link)\n",
    "            \n",
    "        \n",
    "        for link in self.driver_list: #loops through every URL in the list and scrapes the statistics\n",
    "            \n",
    "            #resets the dictionary entry to blank at the beginning of each URL\n",
    "            self.dict_entry={}\n",
    "\n",
    "            #opens each URL in the list\n",
    "            self.driver.get(link)\n",
    "\n",
    "            self.get_driver_name() #gets the Drivers Name and splits it into First name, Surname\n",
    "\n",
    "            #scrapes the data from the different columns\n",
    "            column1_data = self.driver.find_elements(by=By.XPATH, value=\"//div[@class='col-md-6']//td\")\n",
    "            for i in range(0,len(column1_data),2):\n",
    "                    self.dict_entry[column1_data[i].text] = column1_data[i+1].text\n",
    "            column23_data = self.driver.find_elements(by=By.XPATH, value=\"//div[@class='col-md-3']//td\")\n",
    "            for i in range(0,len(column23_data),2):\n",
    "                    self.dict_entry[column23_data[i].text] = column23_data[i+1].text\n",
    "\n",
    "            #add each entry as a nested dictionary\n",
    "            self.driver_dict[uuid.uuid4().hex] = self.dict_entry\n",
    "\n",
    "        #dump to json file\n",
    "        out_file = open(\"driver_data.json\", \"w\")\n",
    "        json.dump(self.driver_dict, out_file, indent = 6)\n",
    "\n",
    "\n",
    "    def navigate_teams(self): # navigates to the list of teams\n",
    "\n",
    "        self.driver.get(self.URL)\n",
    "        time.sleep(2)\n",
    "        navbar = self.driver.find_element(by=By.XPATH, value=\"//div[@class='navbar-nav']\")\n",
    "        teams_button= navbar.find_element(by=By.LINK_TEXT, value = 'Teams')\n",
    "        teams_button.click()\n",
    "        self.get_team_data()\n",
    "\n",
    "    def get_team_name(self): #gets the Drivers Name and splits it into First name, Surname\n",
    "        \n",
    "\n",
    "        Page_Title = self.driver.find_element(by=By.XPATH, value=\"//h1[@class='page-title']\")\n",
    "        Name = Page_Title.text\n",
    "        Team_Name =Name.replace(\"Formula 1\", \"\")\n",
    "        self.dict_entry[\"Team Name\"] = Team_Name\n",
    "        \n",
    "\n",
    "    def get_team_data(self):\n",
    "        \n",
    "        #creates directory for team data\n",
    "        directory = \"team_data\"\n",
    "        parent_dir = \"/home/andrew/AICore_work/Data-Collection-Pipeline/raw_data\"\n",
    "        path = os.path.join(parent_dir, directory)\n",
    "        raw_data = os.mkdir(path)\n",
    "\n",
    "        #find element containing individual driver URLS\n",
    "        starting_letter_tag = self.driver.find_elements(by=By.XPATH, value=\"//div[@class='col-sm-6 col-md-4']\")\n",
    "\n",
    "        #collects all the drivers URLS in a list\n",
    "        for team in starting_letter_tag: \n",
    "\n",
    "            a_tag = team.find_element(By.TAG_NAME, 'a')\n",
    "            link = a_tag.get_attribute('href')\n",
    "            self.team_list.append(link)\n",
    "            \n",
    "        #loops through every URL in the list and scrapes the statistics\n",
    "        for link in self.team_list: \n",
    "            \n",
    "            #resets the dictionary entry to blank at the beginning of each URL\n",
    "            self.dict_entry={}\n",
    "\n",
    "            #opens each page in the list of URLs\n",
    "            self.driver.get(link)\n",
    "\n",
    "            #gets the Drivers Name and strips the \"Formula 1\" from it\n",
    "            self.get_team_name() \n",
    "\n",
    "            #scrape the data from the different tables on each page\n",
    "            team_history_data = self.driver.find_elements(by=By.XPATH, value=\"//div[@class='table-responsive']//tbody[@itemtype='http://schema.org/SportsTeam']//td\")\n",
    "            for i in range(0,len(team_history_data),2):\n",
    "                self.dict_entry[team_history_data[i].text] = team_history_data[i+1].text\n",
    "\n",
    "            team_driver_data = self.driver.find_elements(by=By.XPATH, value=\"//div[@class='col-md-6']//td\")\n",
    "            for i in range(0,len(team_driver_data),2):\n",
    "                self.dict_entry[team_driver_data[i].text] = team_driver_data[i+1].text\n",
    "\n",
    "            team_data = self.driver.find_elements(by=By.XPATH, value=\"//div[@class='col-md-5']//td\")\n",
    "            for i in range(0,len(team_data),2):\n",
    "                self.dict_entry[team_data[i].text] = team_data[i+1].text\n",
    "            \n",
    "            #add each entry as a nested dictionary\n",
    "            self.teams_dict[uuid.uuid4().hex] = self.dict_entry\n",
    "\n",
    "        #dump to json file\n",
    "        out_file = open(\"teams_data.json\", \"w\")\n",
    "        json.dump(self.teams_dict, out_file, indent = 6)\n",
    "\n",
    "\n",
    "    def navigate_champs(self): # navigates to the list of champions\n",
    "\n",
    "        self.driver.get(self.URL)\n",
    "        navbar = self.driver.find_element(by=By.XPATH, value=\"//div[@class='navbar-nav']\")\n",
    "        champs_button= navbar.find_element(by=By.LINK_TEXT, value = 'Champions')\n",
    "        champs_button.click()\n",
    "        self.get_champs_data()\n",
    "\n",
    "    def get_champs_data(self):\n",
    "\n",
    "        #creates directory for driver data\n",
    "        directory = \"champs_data\"\n",
    "        parent_dir = \"/home/andrew/AICore_work/Data-Collection-Pipeline/raw_data\"\n",
    "        path = os.path.join(parent_dir, directory)\n",
    "        raw_data = os.mkdir(path)\n",
    "\n",
    "        #find elements that contain champion info\n",
    "        champs_data = self.driver.find_elements(by=By.XPATH, value=\"//div[@class='table-responsive']//td\")\n",
    "\n",
    "        #loop through elements to separate into data by year\n",
    "        for i in range(0,len(champs_data),4):\n",
    "                self.dict_entry={}\n",
    "                self.dict_entry[\"Year\"] = champs_data[i].text\n",
    "                self.dict_entry[\"Driver\"] = champs_data[i+1].text\n",
    "                self.dict_entry[\"Driver's Team\"] = champs_data[i+2].text\n",
    "                self.dict_entry[\"Winning Team\"] = champs_data[i+3].text\n",
    "                self.champs_dict[uuid.uuid4().hex] = self.dict_entry\n",
    "                \n",
    "        #dump to json file\n",
    "        out_file = open(\"champs_data.json\", \"w\")\n",
    "        json.dump(self.champs_dict, out_file, indent = 6)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    scraper = Scraper(\"https://www.4mula1stats.com/\", webdriver.Chrome())\n",
    "    # directory = \"raw_data\"\n",
    "    # parent_dir = \"/home/andrew/AICore_work/Data-Collection-Pipeline\"\n",
    "    # path = os.path.join(parent_dir, directory)\n",
    "    # raw_data = os.mkdir(path)\n",
    "    scraper.load_and_accept_cookies()\n",
    "    scraper.navigate_drivers()\n",
    "    # scraper.navigate_teams()\n",
    "    # scraper.navigate_champs()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aa77068f38439fea3d523770773ba61bd6d72ba10bc6cca53fd2c1ada3d3a952"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
