{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import uuid\n",
    "import os\n",
    "import json\n",
    "import urllib.request\n",
    "import urllib\n",
    "from selenium.webdriver.common.by import By\n",
    "from cgitb import text\n",
    "from numpy import append\n",
    "from requests import request\n",
    "from selenium import webdriver\n",
    "\n",
    "class Scraper:\n",
    "\n",
    "    def __init__(self, URL : str, driver : webdriver.Chrome, parent_dir:str):\n",
    "        \n",
    "        self.driver = driver\n",
    "        self.team_list = []\n",
    "        self.URL = URL\n",
    "        self.driver_dict={}\n",
    "        self.teams_dict = {}\n",
    "        self.champs_dict = {}\n",
    "        self.dict_entry = {}\n",
    "        directory = \"raw_data\"\n",
    "        path = os.path.join(parent_dir, directory)\n",
    "        if os.path.exists(path) == False:\n",
    "            raw_data = os.mkdir(path)\n",
    "        \n",
    "\n",
    "    def load_and_accept_cookies(self) -> None:\n",
    "\n",
    "        #Open site and accept the cookies\n",
    "        \n",
    "        self.driver.get(self.URL)\n",
    "        accept_button = self.driver.find_element(by=By.XPATH, value=\"//*[@class='btn btn-success acceptGdpr']\")\n",
    "        accept_button.click()\n",
    "        \n",
    "    def navigate_drivers(self): # navigates to the list of drivers\n",
    "\n",
    "        self.driver.get(self.URL)\n",
    "        navbar = self.driver.find_element(by=By.XPATH, value=\"//div[@class='navbar-nav']\").find_element(by=By.LINK_TEXT, value = 'Drivers').click()\n",
    "        self.get_driver_data()\n",
    "\n",
    "    def get_image(self):\n",
    "\n",
    "        img_src = self.driver.find_element(by=By.XPATH, value=\"//img[@class='col-md-3']\").get_attribute('src')\n",
    "        self.download_image(img_src, \"/home/andrew/AICore_work/Data-Collection-Pipeline/driver_images/\", self.get_driver_name())\n",
    "    \n",
    "    def get_URL_list(self,element):\n",
    "\n",
    "            url_list = []\n",
    "            \n",
    "            starting_letter_tag = self.driver.find_elements(by=By.XPATH, value=element)\n",
    "\n",
    "            for pilot in starting_letter_tag: #collects all the drivers URLS in a list\n",
    "\n",
    "                link = pilot.find_element(By.TAG_NAME, 'a').get_attribute('href')\n",
    "                url_list.append(link)\n",
    "\n",
    "            return url_list\n",
    "        \n",
    "    def download_image(self, url, file_path, file_name):\n",
    "        full_path = file_path + file_name + '.jpg'\n",
    "        urllib.request.urlretrieve(url, full_path)\n",
    "\n",
    "    def stripF1_text(self, tobereplaced):\n",
    "        Name = self.driver.find_element(by=By.XPATH, value=\"//h1[@class='page-title']\").text.replace(tobereplaced, \"\")\n",
    "        return Name\n",
    "    \n",
    "    def get_driver_name(self) -> str: #gets the Drivers Name and splits it into First name, Surname and adds it to dictionary\n",
    "        \n",
    "        Name = self.stripF1_text(\"Formula 1 Driver\")\n",
    "        driver_forename = Name.split()[0]\n",
    "        driver_surname = \" \".join(Name.split()[1:len(Name.split())-3])\n",
    "\n",
    "        self.dict_entry[\"Driver First Name\"] = driver_forename\n",
    "        self.dict_entry[\"Driver Second Name\"] = driver_surname\n",
    "        return driver_forename + \"_\" + driver_surname\n",
    "\n",
    "    def get_driver_data(self):\n",
    "        \n",
    "        #creates directory for driver data\n",
    "        self.create_dir(\"driver_data\")\n",
    "\n",
    "        #find element containing individual driver URLS\n",
    "        url_list = self.get_URL_list(\"//div[@class='col-sm-6 col-md-4']\")\n",
    "\n",
    "        \n",
    "        for link in url_list: #loops through every URL in the list and scrapes the statistics\n",
    "            \n",
    "            #resets the dictionary entry to blank at the beginning of each URL\n",
    "            self.dict_entry={}\n",
    "\n",
    "            #opens each URL in the list\n",
    "            self.driver.get(link)\n",
    "\n",
    "            self.get_driver_name() #gets the Drivers Name and splits it into First name, Surname\n",
    "            self.get_image()\n",
    "\n",
    "            #scrapes the data from the different columns\n",
    "            column1_data = self.driver.find_elements(by=By.XPATH, value=\"//div[@class='col-md-6']//td\")\n",
    "            for i in range(0,len(column1_data),2):\n",
    "                    self.dict_entry[column1_data[i].text] = column1_data[i+1].text\n",
    "            column23_data = self.driver.find_elements(by=By.XPATH, value=\"//div[@class='col-md-3']//td\")\n",
    "            for i in range(0,len(column23_data),2):\n",
    "                    self.dict_entry[column23_data[i].text] = column23_data[i+1].text\n",
    "\n",
    "            #add each entry as a nested dictionary\n",
    "            self.driver_dict[uuid.uuid4().hex] = self.dict_entry\n",
    "\n",
    "        #dump to json file\n",
    "        self.dumptojson(self.driver_dict, \"driver_data.json\")\n",
    "\n",
    "    def navigate_teams(self): # navigates to the list of teams\n",
    "\n",
    "        self.driver.get(self.URL)\n",
    "        navbar = self.driver.find_element(by=By.XPATH, value=\"//div[@class='navbar-nav']\").find_element(by=By.LINK_TEXT, value = 'Teams').click()\n",
    "        self.get_team_data()\n",
    "\n",
    "    def get_team_name(self): #gets the Team Name and strips the \"Formula 1\" from it\n",
    "        \n",
    "        Team_Name = self.stripF1_text(\"Formula 1 Driver\")\n",
    "        self.dict_entry[\"Team Name\"] = Team_Name\n",
    "        \n",
    "    def get_team_data(self):\n",
    "        \n",
    "        #creates directory for team data\n",
    "        self.create_dir(\"team_data\")\n",
    "\n",
    "        #find element containing individual driver URLS\n",
    "        url_list = self.get_URL_list(\"//div[@class='col-sm-6 col-md-4']\")\n",
    "            \n",
    "        #loops through every URL in the list and scrapes the statistics\n",
    "        for link in url_list[:5]: \n",
    "            \n",
    "            #resets the dictionary entry to blank at the beginning of each URL\n",
    "            self.dict_entry={}\n",
    "\n",
    "            #opens each page in the list of URLs\n",
    "            self.driver.get(link)\n",
    "\n",
    "            #gets the Drivers Name and strips the \"Formula 1\" from it\n",
    "            self.get_team_name() \n",
    "\n",
    "            #scrape the data from the different tables on each page\n",
    "            team_history_data = self.driver.find_elements(by=By.XPATH, value=\"//div[@class='table-responsive']//tbody[@itemtype='http://schema.org/SportsTeam']//td\")\n",
    "            for i in range(0,len(team_history_data),2):\n",
    "                self.dict_entry[team_history_data[i].text] = team_history_data[i+1].text\n",
    "\n",
    "            team_driver_data = self.driver.find_elements(by=By.XPATH, value=\"//div[@class='col-md-6']//td\")\n",
    "            for i in range(0,len(team_driver_data),2):\n",
    "                self.dict_entry[team_driver_data[i].text] = team_driver_data[i+1].text\n",
    "\n",
    "            team_data = self.driver.find_elements(by=By.XPATH, value=\"//div[@class='col-md-5']//td\")\n",
    "            for i in range(0,len(team_data),2):\n",
    "                self.dict_entry[team_data[i].text] = team_data[i+1].text\n",
    "            \n",
    "            #add each entry as a nested dictionary\n",
    "            self.teams_dict[uuid.uuid4().hex] = self.dict_entry\n",
    "\n",
    "        #dump to json file\n",
    "        self.dumptojson(self.teams_dict, \"teams_data.json\")\n",
    "\n",
    "    def navigate_champs(self): # navigates to the list of champions\n",
    "\n",
    "        self.driver.get(self.URL)\n",
    "        navbar = self.driver.find_element(by=By.XPATH, value=\"//div[@class='navbar-nav']\").find_element(by=By.LINK_TEXT, value = 'Champions').click()\n",
    "        self.get_champs_data()\n",
    "\n",
    "    def get_champs_data(self):\n",
    "\n",
    "        #creates directory for driver data\n",
    "        self.create_dir(\"champs_data\")\n",
    "\n",
    "        #find elements that contain champion info\n",
    "        champs_data = self.driver.find_elements(by=By.XPATH, value=\"//div[@class='table-responsive']//td\")\n",
    "\n",
    "        #loop through elements to separate into data by year\n",
    "        for i in range(0,len(champs_data),4):\n",
    "                self.dict_entry={}\n",
    "                self.dict_entry[\"Year\"] = champs_data[i].text\n",
    "                self.dict_entry[\"Driver\"] = champs_data[i+1].text\n",
    "                self.dict_entry[\"Driver's Team\"] = champs_data[i+2].text\n",
    "                self.dict_entry[\"Winning Team\"] = champs_data[i+3].text\n",
    "                self.champs_dict[uuid.uuid4().hex] = self.dict_entry\n",
    "                \n",
    "        #dump to json file\n",
    "        self.dumptojson(self.champs_dict, \"champs_data.json\")\n",
    "\n",
    "    def create_dir(self,directory):\n",
    "        \n",
    "            parent_dir = \"/home/andrew/AICore_work/Data-Collection-Pipeline/raw_data\"\n",
    "            path = os.path.join(parent_dir, directory)\n",
    "            if os.path.exists(path) == False:\n",
    "                raw_data = os.mkdir(path)\n",
    "\n",
    "    def dumptojson(self, dictionary, out_file):\n",
    "        out_file = open(out_file, \"w\")\n",
    "        json.dump(dictionary, out_file, indent = 6)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    scraper = Scraper(\"https://www.4mula1stats.com/\", webdriver.Chrome(), \"/home/andrew/AICore_work/Data-Collection-Pipeline\")\n",
    "    scraper.load_and_accept_cookies()\n",
    "    #scraper.navigate_drivers()\n",
    "    scraper.navigate_teams()\n",
    "    scraper.navigate_champs()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aa77068f38439fea3d523770773ba61bd6d72ba10bc6cca53fd2c1ada3d3a952"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
